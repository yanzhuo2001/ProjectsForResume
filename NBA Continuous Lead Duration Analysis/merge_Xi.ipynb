{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T22:28:43.901865Z",
     "start_time": "2024-03-03T22:28:43.583343Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "years = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "file_path = []\n",
    "year_range = []\n",
    "for i in range(0, len(years)-1):\n",
    "    year_range.append(str(years[i])+'-'+str(years[i+1]))\n",
    "    file_path.append('data/'+year_range[i]+'/')\n",
    "    \n",
    "file_name_cuts = ['league_defense_halfcourt_and_putbacks_', 'league_defense_shooting_accuracy_', 'league_defense_shooting_frequency_', 'league_defense_transition_', 'league_four_factors_', 'league_offense_halfcourt_and_putbacks_', 'league_offense_shooting_accuracy_', 'league_offense_shooting_frequency_', 'league_offense_transition_', 'league_summary_']\n",
    "\n",
    "file_names = []\n",
    "for i in range(0, len(year_range)):\n",
    "    for j in range(0, len(file_name_cuts)):\n",
    "        file_names.append(file_path[i]+file_name_cuts[j]+year_range[i]+'.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T22:28:43.905470Z",
     "start_time": "2024-03-03T22:28:43.901865Z"
    }
   },
   "id": "e61880cf5c006384",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def rename_columns(filename):\n",
    "#     # 读取CSV文件\n",
    "#     df = pd.read_csv(filename)\n",
    "#     # 删除列名以 \"LAST 2 WEEKS: \" 开头的列\n",
    "#     df = df.drop(columns=[col for col in df.columns if col.startswith('LAST 2 WEEKS: ')])\n",
    "#     # 删除所有包含 \"rank\" 的列（不论大小写）\n",
    "#     df = df.drop(columns=[col for col in df.columns if \"rank\" in col.lower()], errors='ignore')\n",
    "#     \n",
    "#     # 检查文件名中包含的关键字，并设置相应的前缀\n",
    "#     if 'offense' in filename:\n",
    "#         prefix = 'offense_'\n",
    "#     elif 'defense' in filename:\n",
    "#         prefix = 'defense_'\n",
    "#     else:\n",
    "#         prefix = ''\n",
    "#     \n",
    "#     # 重命名列\n",
    "#     new_columns = {col: prefix + col.replace(': ', '_') for col in df.columns}\n",
    "#     df.rename(columns=new_columns, inplace=True)\n",
    "#     new_columns2 = {col: col.replace(' ', '_') for col in df.columns}\n",
    "#     df.rename(columns=new_columns2, inplace=True)\n",
    "#     \n",
    "#     # 确保每个列名前缀只出现一次\n",
    "#     def normalize_prefix(col_name):\n",
    "#         # 使用正则表达式移除重复的前缀\n",
    "#         col_name = re.sub(r'^(offense_|defense_)+', prefix, col_name)\n",
    "#         return col_name\n",
    "#     \n",
    "#     new_columns3 = {col: normalize_prefix(new_name) for col, new_name in new_columns2.items()}\n",
    "#         \n",
    "#     # 将含有 \"team\" 的列名重命名为 \"Team\"\n",
    "#     new_columns4 = {col: re.sub(r'defense_Team', 'Team', new_name) for col, new_name in new_columns3.items()}\n",
    "#     \n",
    "#     new_columns5 = {col: re.sub(r'offense_Team', 'Team', new_name) for col, new_name in new_columns4.items()}\n",
    "#     \n",
    "#     # 应用新的列名\n",
    "#     df.rename(columns=new_columns5, inplace=True)\n",
    "# \n",
    "#     # 保存修改后的CSV文件\n",
    "#     df.to_csv(filename, index=False)\n",
    "#     \n",
    "# for filename in file_names:\n",
    "#     rename_columns(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T22:28:45.449401Z",
     "start_time": "2024-03-03T22:28:43.906586Z"
    }
   },
   "id": "f419b17a17411fb4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for i in range(0, len(year_range)):\n",
    "#     df_separated_years = []\n",
    "#     for j in range(i*10, i*10+10):\n",
    "#         df_separated_years.append(pd.read_csv(file_names[j]))\n",
    "#     \n",
    "#     merged_df = reduce(lambda left, right: pd.merge(left, right, on='Team', how='outer'), df_separated_years)\n",
    "#     \n",
    "#     merged_df.to_csv(file_path[i]+f'merged_{year_range[i]}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T22:30:58.861986Z",
     "start_time": "2024-03-03T22:30:58.205867Z"
    }
   },
   "id": "ce9a0638503b9253",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_merged_years = []\n",
    "for i in range(0, len(year_range)):\n",
    "    file_merged_years.append(file_path[i]+f'merged_{year_range[i]}.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T22:51:40.363126Z",
     "start_time": "2024-03-03T22:51:40.359612Z"
    }
   },
   "id": "3e0b4c41400b55a8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f9abd098aeb0065"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
